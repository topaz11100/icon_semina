# pFedMoE 발표 예상 질문 및 답변

## 이론적 질문

### Q1: MoE 구조에서 게이팅 네트워크가 어떻게 작동하는지 더 자세히 설명해주실 수 있나요?
**답변**: 게이팅 네트워크는 입력 데이터 샘플을 받아 각 전문가 모델에 대한 가중치를 생성합니다. 우리의 pFedMoE에서는 두 개의 전문가(글로벌 전문가와 로컬 전문가)가 있으며, 게이팅 네트워크는 경량 선형 네트워크로 구현되어 있습니다. 

구체적으로, 게이팅 네트워크는 입력 데이터에 대해 소프트맥스 함수를 사용하여 두 전문가의 출력에 적용할 확률 분포를 생성합니다. 이 확률 분포는 각 데이터 샘플의 특성에 따라 달라지며, 이를 통해 데이터 수준의 개인화가 가능해집니다. 예를 들어, 로컬 데이터와 유사한 샘플에 대해서는 로컬 전문가에 더 높은 가중치를 부여하고, 글로벌 데이터와 유사한 샘플에 대해서는 글로벌 전문가에 더 높은 가중치를 부여할 수 있습니다.

### Q2: pFedMoE의 수렴성을 O(1/T)로 증명하셨는데, 이는 다른 연합학습 방법과 비교해서 어떤 의미가 있나요?
**답변**: O(1/T) 수렴 속도는 비볼록 최적화 문제에서 일반적인 수렴 속도입니다. 우리의 증명은 pFedMoE가 이론적으로 견고하며 시간이 지남에 따라 안정적으로 수렴함을 보장합니다.

다른 연합학습 방법과 비교할 때, 우리의 방법은 모델 이종성을 지원하면서도 이러한 수렴성을 유지한다는 점이 중요합니다. 많은 기존 방법들은 모델 동종성을 가정하거나, 이종성을 지원하더라도 수렴성 증명이 부족한 경우가 많습니다. 우리는 특정 학습률 조건 하에서 모든 클라이언트의 로컬 이종 모델이 수렴할 수 있음을 증명했습니다.

또한, 이 수렴 속도는 우리 방법이 실제 구현에서도 안정적으로 작동할 것임을 시사합니다. 실험 결과에서 보듯이, pFedMoE는 다양한 설정에서 일관되게 좋은 성능을 보여주었습니다.

### Q3: 동종 작은 특징 추출기와 이종 대형 모델 간의 균형을 어떻게 결정했나요? 이 비율이 성능에 미치는 영향은 무엇인가요?
**답변**: 동종 작은 특징 추출기와 이종 대형 모델 간의 균형은 실험적으로 결정했습니다. 우리는 다양한 모델 구성을 테스트하여 최적의 균형을 찾았습니다.

특징 추출기의 크기는 통신 비용과 직접적인 관련이 있습니다. 너무 큰 특징 추출기는 통신 오버헤드를 증가시키고, 너무 작은 특징 추출기는 일반화된 특징을 충분히 추출하지 못할 수 있습니다. 우리는 충분한 표현력을 가지면서도 통신 효율성을 유지할 수 있는 크기를 선택했습니다.

실험 결과, 이 균형이 성능에 상당한 영향을 미치는 것을 확인했습니다. 특히, 모델 이종성 + 동종 추출기 구성에서 우리의 방법이 좋은 성능을 보였습니다. 이는 작은 동종 특징 추출기가 클라이언트 간 지식 공유를 효과적으로 촉진하면서도, 이종 대형 모델이 로컬 데이터에 대한 개인화를 제공할 수 있기 때문입니다.

## 실험 관련 질문

### Q4: 실험에서 사용한 non-IID 데이터 분포는 어떻게 생성했나요? 실제 환경의 데이터 이질성을 얼마나 잘 반영한다고 생각하시나요?
**답변**: 우리는 CIFAR-10과 CIFAR-100 데이터셋을 사용하여 non-IID 데이터 분포를 생성했습니다. 구체적으로, 각 클라이언트가 전체 클래스 중 일부 클래스의 데이터만 가지도록 데이터를 분할했습니다. 예를 들어, CIFAR-10에서 각 클라이언트는 10개 클래스 중 2개 클래스의 데이터만 가지도록 설정했습니다(2/10 non-IID 설정).

이러한 방식은 실제 환경에서 발생할 수 있는 데이터 이질성의 한 측면을 모델링합니다. 실제로 다양한 기관이나 사용자는 특정 유형의 데이터에만 접근할 수 있는 경우가 많습니다. 예를 들어, 의료 기관은 특정 질병에 관한 데이터를 더 많이 보유할 수 있습니다.

물론, 실제 환경의 데이터 이질성은 더 복잡할 수 있습니다. 클래스 불균형뿐만 아니라 특성 분포의 차이, 레이블 노이즈 등 다양한 요소가 있을 수 있습니다. 향후 연구에서는 더 다양한 유형의 데이터 이질성을 고려한 실험을 수행할 계획입니다.

### Q5: 다른 MHPFL 방법들과 비교했을 때, pFedMoE의 계산 복잡도와 통신 비용은 어떻게 되나요?
**답변**: pFedMoE는 계산 복잡도와 통신 비용 측면에서 효율적입니다. 

계산 복잡도 측면에서, 우리 방법은 MoE와 예측 헤더를 동시에 업데이트하여 계산 비용을 절감합니다. 기존의 상호 학습 기반 방법(예: FedAPEN)은 먼저 가중치를 학습한 다음 모델을 번갈아 학습하므로 추가 계산 비용이 발생합니다. 우리의 실험에서 pFedMoE는 이러한 방법들보다 낮은 계산 비용을 보였습니다.

통신 비용 측면에서, 우리 방법은 작은 동종 특징 추출기만 서버와 교환하므로 통신 효율성이 높습니다. 지식 증류 기반 방법(예: FedProto)은 각 공개 데이터 샘플에 대한 로짓이나 표현을 통신해야 하므로 더 높은 통신 비용이 발생할 수 있습니다.

구체적인 수치로, 우리의 실험에서 pFedMoE는 기존 방법들과 비교하여 최대 30%의 계산 비용 감소와 허용 가능한 통신 비용을 보였습니다.

### Q6: 모델 이종성의 정도가 성능에 미치는 영향을 분석하셨나요? 클라이언트 간 모델 구조 차이가 클수록 성능이 어떻게 변화하나요?
**답변**: 네, 우리는 모델 이종성의 정도가 성능에 미치는 영향을 분석했습니다. 실험에서 5가지 다른 CNN 모델 구조(CNN-1부터 CNN-5까지)를 사용했으며, 이들은 모델 크기와 복잡도가 다양합니다.

일반적으로, 클라이언트 간 모델 구조 차이가 클수록 기존 방법들의 성능은 저하되는 경향이 있습니다. 특히, 모델 혼합 기반 방법들은 동종 부분만 공유하므로 모델 구조 차이가 클 때 성능이 크게 떨어질 수 있습니다.

그러나 pFedMoE는 모델 구조 차이가 클 때도 안정적인 성능을 유지했습니다. 이는 우리 방법이 게이팅 네트워크를 통해 각 데이터 샘플에 대해 적응적으로 글로벌 지식과 로컬 지식을 결합하기 때문입니다. 특히, 모델 이종성이 큰 환경에서 pFedMoE는 기존 최고 방법보다 최대 2.80% 정확도 향상을 보였습니다.

## 적용 및 확장 관련 질문

### Q7: pFedMoE를 실제 산업 환경에 적용할 때 고려해야 할 주요 도전 과제는 무엇인가요?
**답변**: pFedMoE를 실제 산업 환경에 적용할 때 고려해야 할 몇 가지 주요 도전 과제가 있습니다:

1. **확장성**: 대규모 클라이언트 환경에서의 확장성 문제입니다. 우리의 실험은 최대 100개 클라이언트를 고려했지만, 실제 환경에서는 수천, 수만 개의 클라이언트가 있을 수 있습니다. 이러한 환경에서 효율적인 클라이언트 선택 및 집계 전략이 필요합니다.

2. **이기종 하드웨어**: 다양한 하드웨어 환경에서의 구현 문제입니다. 특히 리소스가 제한된 엣지 디바이스에서 MoE 구조를 효율적으로 구현하는 것이 중요합니다.

3. **통신 제약**: 불안정한 네트워크 환경에서의 통신 문제입니다. 동기식 집계를 가정하는 현재 방법을 비동기식 환경으로 확장할 필요가 있습니다.

4. **보안 및 프라이버시**: 모델 파라미터 교환 과정에서의 추가적인 보안 고려사항입니다. 차등 프라이버시나 안전한 집계와 같은 기술을 통합할 수 있습니다.

이러한 도전 과제를 해결하기 위해 현재 추가 연구를 진행 중이며, 산업 파트너와 협력하여 실제 환경에서의 테스트를 계획하고 있습니다.

### Q8: pFedMoE를 컴퓨터 비전 이외의 다른 도메인(예: 자연어 처리, 추천 시스템)에 적용할 수 있을까요?
**답변**: 네, pFedMoE는 컴퓨터 비전 이외의 다른 도메인에도 적용 가능한 일반적인 프레임워크입니다. 

자연어 처리(NLP) 도메인에서는 BERT나 GPT와 같은 다양한 크기와 구조의 언어 모델을 클라이언트가 사용할 수 있습니다. pFedMoE를 통해 작은 공유 임베딩 레이어와 로컬 트랜스포머 레이어를 결합하여 효과적인 개인화된 언어 모델을 구축할 수 있습니다.

추천 시스템에서는 사용자마다 다른 선호도 패턴을 가지고 있어 개인화가 특히 중요합니다. pFedMoE는 글로벌 아이템 임베딩과 로컬 사용자 모델을 결합하여 개인화된 추천을 제공할 수 있습니다.

의료 분야에서는 다양한 병원이나 기관이 서로 다른 모델 구조를 사용하는 경우가 많습니다. pFedMoE는 이러한 이종 모델 간의 지식 공유를 가능하게 하면서도 각 기관의 데이터 특성에 맞는 개인화를 제공할 수 있습니다.

현재 우리는 이러한 다양한 도메인에 pFedMoE를 적용하는 후속 연구를 진행 중입니다.

### Q9: 게이팅 네트워크의 구조를 더 복잡하게 만들면 성능이 향상될까요? 어떤 트레이드오프가 있을까요?
**답변**: 게이팅 네트워크의 구조를 더 복잡하게 만들면 이론적으로는 더 정교한 가중치 할당이 가능해져 성능이 향상될 수 있습니다. 그러나 이에는 몇 가지 중요한 트레이드오프가 있습니다:

1. **계산 복잡도**: 더 복잡한 게이팅 네트워크는 계산 비용을 증가시킵니다. 특히 리소스가 제한된 엣지 디바이스에서는 이것이 중요한 제약이 될 수 있습니다.

2. **과적합 위험**: 복잡한 게이팅 네트워크는 로컬 데이터에 과적합될 위험이 있습니다. 이는 일반화 성능을 저하시킬 수 있습니다.

3. **수렴 안정성**: 복잡한 게이팅 네트워크는 학습 과정을 불안정하게 만들 수 있으며, 수렴을 더 어렵게 만들 수 있습니다.

우리의 실험에서는 단일 선형 레이어로 구성된 경량 게이팅 네트워크가 이러한 트레이드오프를 잘 균형 잡는 것으로 나타났습니다. 그러나 특정 도메인이나 태스크에 따라 최적의 게이팅 네트워크 구조는 달라질 수 있으며, 이는 향후 연구에서 더 탐구할 가치가 있는 부분입니다.

## 미래 연구 방향 관련 질문

### Q10: 이 연구의 가장 중요한 한계점은 무엇이며, 이를 해결하기 위한 향후 연구 방향은 어떻게 되나요?
**답변**: 우리 연구의 주요 한계점과 향후 연구 방향은 다음과 같습니다:

1. **동적 환경 지원**: 현재 pFedMoE는 정적인 클라이언트 집합을 가정합니다. 향후 연구에서는 클라이언트가 동적으로 참여하고 떠나는 환경에서도 효과적으로 작동하도록 확장할 계획입니다.

2. **다양한 데이터 이질성**: 현재 실험은 클래스 불균형 기반의 non-IID 설정에 초점을 맞추었습니다. 향후에는 특성 분포 차이, 레이블 노이즈 등 더 다양한 유형의 데이터 이질성을 고려할 것입니다.

3. **전문가 수 확장**: 현재 구현에서는 두 개의 전문가(글로벌 및 로컬)만 고려했습니다. 향후에는 다중 전문가 설정으로 확장하여 더 세분화된 지식 분할을 탐구할 계획입니다.

4. **프라이버시 강화**: 현재 방법은 기본적인 데이터 프라이버시를 제공하지만, 차등 프라이버시나 연합 학습을 위한 안전한 집계와 같은 추가적인 프라이버시 보호 메커니즘을 통합할 수 있습니다.

5. **지속적 학습**: 데이터 분포가 시간에 따라 변화하는 환경에서의 지속적 학습 시나리오를 탐구할 계획입니다.

이러한 방향으로의 연구를 통해 pFedMoE의 실용성과 적용 범위를 더욱 확장할 수 있을 것으로 기대합니다.

### Q11: 최근 LLM과 같은 초대형 모델의 등장으로 연합학습 패러다임이 어떻게 변화할 것으로 예상하시나요? pFedMoE가 이러한 변화에 어떻게 기여할 수 있을까요?
**답변**: LLM과 같은 초대형 모델의 등장으로 연합학습 패러다임은 크게 변화하고 있습니다. 이러한 변화와 pFedMoE의 기여 가능성은 다음과 같습니다:

1. **계산 효율성의 중요성 증가**: 초대형 모델은 엄청난 계산 자원을 요구하므로, 전체 모델을 각 클라이언트에서 학습하는 것은 현실적으로 불가능합니다. pFedMoE의 MoE 기반 접근 방식은 계산 효율성을 제공하며, 각 데이터 샘플에 대해 필요한 전문가만 활성화함으로써 자원 사용을 최적화할 수 있습니다.

2. **부분 모델 학습**: 초대형 모델의 경우 각 클라이언트가 전체 모델의 일부만 학습하는 방식이 중요해지고 있습니다. pFedMoE의 모델 이종성 지원은 이러한 시나리오에 자연스럽게 적용될 수 있습니다.

3. **개인화의 중요성**: LLM은 일반적인 지식을 잘 포착하지만, 특정 도메인이나 사용자에 대한 개인화가 여전히 중요한 과제입니다. pFedMoE의 데이터 수준 개인화 접근 방식은 LLM의 일반 지식과 로컬 개인화를 효과적으로 결합할 수 있습니다.

4. **지식 증류와의 결합**: 최근 LLM에서는 지식 증류가 중요한 기법으로 사용되고 있습니다. pFedMoE의 프레임워크는 지식 증류와 결합하여 대형 글로벌 모델의 지식을 작은 로컬 모델로 효율적으로 전달할 수 있는 가능성이 있습니다.

우리는 현재 pFedMoE를 LLM 맥락에서 확장하는 연구를 진행 중이며, 특히 파라미터 효율적인 미세 조정 기법과의 결합을 탐구하고 있습니다.

### Q12: 연합학습에서 공정성(fairness)과 편향(bias) 문제를 어떻게 다루고 계신가요? pFedMoE가 이러한 문제를 완화하는 데 도움이 될 수 있을까요?
**답변**: 연합학습에서 공정성과 편향 문제는 매우 중요한 고려사항입니다. 특히 다양한 클라이언트가 참여하는 환경에서는 일부 클라이언트나 데이터 그룹이 불이익을 받지 않도록 보장하는 것이 중요합니다.

pFedMoE는 다음과 같은 방식으로 이러한 문제를 완화하는 데 도움이 될 수 있습니다:

1. **개인화를 통한 공정성 향상**: pFedMoE의 데이터 수준 개인화는 각 클라이언트가 자신의 로컬 데이터 특성에 맞는 모델을 가질 수 있게 합니다. 이는 소수 그룹이나 비표준적인 데이터 분포를 가진 클라이언트도 좋은 성능을 얻을 수 있게 도와줍니다.

2. **모델 이종성 지원**: 다양한 리소스를 가진 클라이언트들이 자신의 능력에 맞는 모델을 사용할 수 있게 함으로써 리소스 불평등으로 인한 불공정성을 줄일 수 있습니다.

3. **게이팅 메커니즘의 활용**: 게이팅 네트워크를 공정성 인식(fairness-aware) 방식으로 설계하면, 소외된 그룹의 데이터에 대해 더 많은 주의를 기울이도록 할 수 있습니다.

현재 우리는 pFedMoE에 명시적인 공정성 제약 조건을 통합하는 후속 연구를 진행 중입니다. 이를 통해 다양한 공정성 메트릭(예: 그룹 간 성능 격차 최소화)을 최적화하면서도 전체 모델 성능을 유지하는 방법을 탐구하고 있습니다.

또한, 데이터 편향을 감지하고 완화하기 위한 메커니즘을 pFedMoE 프레임워크에 통합하는 방안도 연구 중입니다.
